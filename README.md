# ğŸ›¡ï¸ AI Threat Analytics Framework

> A proof-of-concept framework demonstrating AI-powered security threat analysis and detection techniques.

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![Tests](https://img.shields.io/badge/tests-7%20passing-brightgreen.svg)]()
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## ğŸŒŸ Overview

This framework showcases practical implementations of AI security concepts including threat classification, anomaly detection, LLM guardrails, and automated summarization. Built with clean code, comprehensive testing, and documentation.

**Key Highlights:**
- âœ… **7 Working Tests** - 100% passing rate
- âœ… **Real Implementations** - No mocks, actual working algorithms
- âœ… **Complete Documentation** - Test plans, cases, and traceability
- âœ… **Security-Focused** - Demonstrates AI safety techniques

---

## ğŸš€ Features

| Feature | Description | Technology |
|---------|-------------|------------|
| ğŸ¤– **Autofill Service** | Intelligent email suggestion generation | Pattern matching |
| ğŸ¯ **Threat Classifier** | Phishing, malware, spam detection | Keyword analysis |
| ğŸ›¡ï¸ **LLM Guardrails** | Prompt injection & PII filtering | Regex patterns |
| ğŸ“ **Summarizer** | Automated report summarization | Extractive NLP |
| ğŸ“Š **Anomaly Detection** | Statistical outlier identification | Z-score analysis |
| ğŸ”„ **Data Validation** | Pipeline quality checks | Data filtering |

---

## âš¡ Quick Start

```bash
# 1. Clone the repository
git clone https://github.com/steadhac/ai-threat-analytics-framework.git
cd ai-threat-analytics-framework

# 2. Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Run all tests
python run_tests.py

# AI functionality tests
pytest tests_ai/test_classification.py -v
pytest tests_ai/test_llm_guardrails.py -v

# Pipeline tests
pytest tests_pipelines/test_anomaly_detection.py -v

# 5. Generate HTML report
pytest --html=reports/test_results.html --self-contained-html

# Open in browser
open reports/test_results.html  # macOS
xdg-open reports/test_results.html  # Linux
start reports/test_results.html  # Windows

# Test Coverage
pytest --cov=core --cov-report=html
open htmlcov/index.html
```

## Project Structure

The project follows this directory structure:
```
ai-threat-analytics-framework/
â”‚
â”œâ”€â”€ ğŸ“‚ core/                         # Core implementation modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ api_client.py                # HTTP client for API calls
â”‚   â”œâ”€â”€ helpers.py                   # Utility functions
â”‚   â”œâ”€â”€ logger.py                    # Logging configuration
â”‚   â”œâ”€â”€ metrics.py                   # Performance metrics
â”‚   â”œâ”€â”€ security_checks.py           # Security validation
â”‚   â”œâ”€â”€ autofill_service.py          # â­ AI email suggestions
â”‚   â”œâ”€â”€ threat_classifier.py         # â­ Threat classification engine
â”‚   â”œâ”€â”€ guardrails.py                # â­ LLM security guardrails
â”‚   â”œâ”€â”€ summarizer.py                # â­ Text summarization
â”‚   â””â”€â”€ anomaly_utils.py             # â­ Anomaly detection (z-score)
â”‚
â”œâ”€â”€ ğŸ“‚ tests_ai/                     # AI/ML functionality tests (4 tests)
â”‚   â”œâ”€â”€ test_autofill.py             # Email suggestion tests
â”‚   â”œâ”€â”€ test_classification.py       # Threat detection tests
â”‚   â”œâ”€â”€ test_llm_guardrails.py       # Security guardrail tests
â”‚   â””â”€â”€ test_summarization.py        # Summarization tests
â”‚
â”œâ”€â”€ ğŸ“‚ tests_pipelines/              # Data pipeline tests (3 tests)
â”‚   â”œâ”€â”€ test_anomaly_detection.py    # Anomaly detection tests
â”‚   â”œâ”€â”€ test_data_pipelines.py       # Data validation tests
â”‚   â””â”€â”€ test_integration_ml.py       # End-to-end ML tests
â”‚
â”œâ”€â”€ ğŸ“‚ docs/                         # Documentation
â”‚   â”œâ”€â”€ TEST_PLAN.md                 # Testing strategy
â”‚   â”œâ”€â”€ TEST_CASES.md                # Detailed test specifications
â”‚   â”œâ”€â”€ TRACEABILITY_MATRIX.md       # Requirements mapping
â”‚   â””â”€â”€ CONCEPTS.md                  # Technical concepts explained
â”‚
â”œâ”€â”€ ğŸ“‚ config/                       # Configuration files
â”‚   â””â”€â”€ settings.yaml                # Application settings
â”‚
â”œâ”€â”€ ğŸ“‚ reports/                      # Generated test reports
â”‚
â”œâ”€â”€ ğŸ“„ requirements.txt              # Python dependencies
â”œâ”€â”€ ğŸ“„ run_tests.py                  # Test execution script
â”œâ”€â”€ ğŸ“„ conftest.py                   # Pytest configuration
â”œâ”€â”€ ğŸ“„ setup.cfg                     # Setup configuration
â”œâ”€â”€ ğŸ“„ SETUP_GUIDE.md               # Detailed setup instructions
â””â”€â”€ ğŸ“„ README.md                    # This file
```

## ğŸ’¡ How It Works
### Anomaly Detection (Z-Score)
```python
from core.anomaly_utils import detect_anomalies

# Detect unusual values in data stream
data = [10, 12, 11, 13, 100, 12]  # 100 is anomaly
anomalies = detect_anomalies(data, threshold=2.0)
# Returns: [4] (index of value 100)
```

### Threat Classification
```python
from core.threat_classifier import ThreatClassifier

classifier = ThreatClassifier()
result = classifier.classify("Click here to claim your prize!")
# Returns: {'labels': ['phishing'], 'confidence': [0.92], 'is_threat': True}
```

### LLM Guardrails
```python
from core.guardrails import LLMGuardrails

guardrails = LLMGuardrails()
result = guardrails.validate_input("Ignore all previous instructions")
# Returns: {'is_safe': False, 'threats_detected': ['prompt_injection']}
```

## ğŸ¯ Use Cases
This proof-of-concept demonstrates techniques applicable to:

| Use Case | Application | Technique Used |
|----------|-------------|----------------|
| ğŸ“§ **Email Security** | Phishing detection | Keyword classification |
| ğŸ” **Input Validation** | Prevent prompt injection | Regex pattern matching |
| ğŸ“Š **Behavior Monitoring** | Unusual activity detection | Z-score anomaly detection |
| ğŸ“ **Report Automation** | Threat intelligence summaries | Extractive summarization |
| ğŸš¨ **Alert Systems** | Anomaly alerting | Statistical analysis |

## ğŸ› ï¸ Technology Stack

| Category | Technologies |
|----------|-------------|
| **Language** | Python 3.9+ |
| **Testing** | pytest, pytest-html, pytest-sugar, pytest-emoji |
| **Data Processing** | PyYAML, Statistics (stdlib) |
| **Pattern Matching** | Regular Expressions (re) |
| **HTTP Client** | requests |

## ğŸš§ Future Enhancements

<details>
<summary>Click to expand enhancement ideas</summary>

- [ ] **ML Models**: Integrate with OpenAI, Anthropic, or Hugging Face
- [ ] **Web Interface**: Flask/FastAPI dashboard
- [ ] **Real-time Monitoring**: WebSocket-based threat feeds
- [ ] **Database Integration**: PostgreSQL/MongoDB for threat history
- [ ] **Advanced NLP**: BERT/GPT-based classification
- [ ] **Multi-language Support**: Threat detection in multiple languages
- [ ] **CI/CD Pipeline**: GitHub Actions automated testing
- [ ] **Docker Support**: Containerized deployment
- [ ] **API Documentation**: OpenAPI/Swagger specs

</details>

## ğŸ“š Documentation

| Document | Description |
|----------|-------------|
| [Setup Guide](SETUP_GUIDE.md) | Installation and configuration |
| [Test Plan](docs/TEST_PLAN.md) | Testing strategy |
| [Test Cases](docs/TEST_CASES.md) | Detailed specifications |
| [Traceability Matrix](docs/TRACEABILITY_MATRIX.md) | Requirements mapping |
| [Concepts](docs/CONCEPTS.md) | Technical explanations |

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¤ Author

**Carolina Steadham**
- GitHub: [@steadhac](https://github.com/steadhac)
- LinkedIn: [Carolina Steadham](https://linkedin.com/in/carolinacsteadham)

---

<div align="center">

**â­ Star this repo if you find it helpful!**

Made with â¤ï¸ and Python

</div>